# Week 3: Data-parallel training

* Slides: [pdf](https://disk.yandex.ru/i/a9P_Ub9Q-Aj5AQ), [source](https://disk.yandex.ru/i/9mafw1A4kL2VJA)
* Lecture: [video1](https://disk.yandex.ru/i/79er4QA2euMdew), [video2](https://disk.yandex.ru/i/-TOM6-lZiJ1FQA)
* Seminar: [link](./seminar.ipynb)
* Homework: see the [homework](./homework) folder

## Further reading
* [Python multiprocessing docs](https://docs.python.org/3/library/multiprocessing.html) (pay attention to `fork` vs `spawn`!)
* [PyTorch Distributed tutorial](https://pytorch.org/tutorials/intermediate/dist_tuto.html)
* [Collective communication protocols in NCCL](https://images.nvidia.com/events/sc15/pdfs/NCCL-Woolley.pdf)
